{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9f507cc",
   "metadata": {},
   "source": [
    "# Gambler's problem (Dynamic programming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6df8844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f87b2c",
   "metadata": {},
   "source": [
    "## 1. Introduction and Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a765d1f",
   "metadata": {},
   "source": [
    "*(Based on Example 4.3 in Sutton & Barto)*\n",
    "\n",
    "A gambler has the opportunity to make bets on the outcomes of a sequence of coin flips. If the coin comes up heads, he wins as many dollars as he has staked on that flip; if it is tails, he loses his stake.\n",
    "The coin has a probability of $p_h = 0.4$ of coming up heads.\n",
    "The player starts with some integer amount of money between $1 and $99.\n",
    "\n",
    "The game ends when the gambler wins by reaching his goal of $100, or loses by running out of money.\n",
    "On each flip, the gambler must decide what portion of his capital to stake, a positive integer number of dollars.\n",
    "The player cannot cash out, he must play until he wins or loses.\n",
    "Since there is only a total of $100 at the table, the gambler cannot place a bet that would cause him to have more than $100 after a win.\n",
    "This problem can be formulated as an undiscounted, episodic, finite MDP. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ccf2ce6",
   "metadata": {},
   "source": [
    "Identify the state-space, possible actions (per state), and reward/transition probabilities.\n",
    "\n",
    "State-space: $ s \\in S$ with\n",
    "$$S = \\{ 0, 1, \\ldots, 99, 100\\} $$\n",
    "\n",
    "Possible actions in state $s$: $a \\in A(s)$ with\n",
    "$$A(s) = \\{ 1, 2, \\ldots, \\min(s, 100-s)\\} $$\n",
    "\n",
    "Rewards/transition probabilites:\n",
    "$$ p(s', r|s, a) = ...? $$\n",
    "\n",
    "$$ p(s + a|s, a) = 0.4 $$\n",
    "$$ p(s - a|s, a) = 0.6 $$\n",
    "\n",
    "If $s' = 100$, $R = 1$. For all other states $s'$, $R=0$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "335e5d83",
   "metadata": {},
   "source": [
    "Assign the values mentioned in the description to the constants below. (*Sidenote: in Python, there are no constants, but by convention, we use all caps for variables that are not supposed to be changed.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b58b0822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Money goal to reach\n",
    "MAX_MONEY = 100\n",
    "\n",
    "# Possible values of probability of the coin coming up heads\n",
    "P_HEADS =  0.4\n",
    "\n",
    "# Small number determining the accuracy of policy evaluation's estimation\n",
    "THETA = 1e-5\n",
    "\n",
    "# Discount factor (can be 1, since this is an episodic task)\n",
    "GAMMA = 1\n",
    "\n",
    "# A list/array of all possible states\n",
    "STATES = np.arange(MAX_MONEY + 1)\n",
    "\n",
    "ACTIONS = np.arange(1, 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "808b61d2",
   "metadata": {},
   "source": [
    "## 2. Policy Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "558ec238",
   "metadata": {},
   "source": [
    "In this section we evaluate a given deterministic policy $\\pi$ by computing the state-value function $v_{\\pi}$.\n",
    "\n",
    "Define the policy you want to evaluate as an array `policy` of adequate length, where `policy[s]` is the action to take when the gambler's capital is `s`.\n",
    "\n",
    "Initialize the value function as an array `values` of adequate length, where `values[s]` is the value of state `s`. Make sure that terminal states have value zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f839c660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1    2    3    4    5    6    7    8    9    10  ...   90   91   92  \\\n",
       "0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1    1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2    1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3    1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4    1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "96   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "97   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "98   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "99   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "100  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "      93   94   95   96   97   98   99  \n",
       "0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "..   ...  ...  ...  ...  ...  ...  ...  \n",
       "96   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "97   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "98   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "99   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "100  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[101 rows x 99 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use length `MAX_MONEY + 1` to include the terminal state\n",
    "policy = [1] * len(STATES) # always bet 1 chf\n",
    "policy = np.zeros((len(STATES), len(ACTIONS)))\n",
    "policy[1:100,0] = 1\n",
    "policy = pd.DataFrame(policy)\n",
    "policy.rename(columns=dict(zip(range(99), range(1, 100))), inplace=True)\n",
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33c84509",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.zeros(MAX_MONEY + 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c2589ff",
   "metadata": {},
   "source": [
    "First, we implement a helper function that evaluates an action `a` for a given state `s`, using the current value function `currentValues`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a1ef0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalAction(s, a, currentValues):\n",
    "    # If we are already in a terminal state, return 0\n",
    "    if s in (0, 100):\n",
    "        return 0\n",
    "    \n",
    "    # Check that s+a and s-a are valid states (optional)\n",
    "    if s-a < 0 or s+a > MAX_MONEY:\n",
    "        raise Exception('invalid action/state')\n",
    "\n",
    "    # Compute and return the expected reward + value of the next state\n",
    "    if s + a == MAX_MONEY:\n",
    "        eReward = P_HEADS * 1\n",
    "    else:\n",
    "        eReward = 0\n",
    "    \n",
    "    eValue = currentValues[(s+a)] * P_HEADS + currentValues[(s-a)] * (1-P_HEADS)\n",
    "\n",
    "    return GAMMA * eValue + eReward\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf05c493",
   "metadata": {},
   "source": [
    "Implement iterative policy evaluation. You can follow the pseudo-code on page 75 in Sutton & Barto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2ddf49e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iteration 10: delta = 0.022295347199999982\n",
      " Iteration 20: delta = 0.007099487911296359\n",
      " Iteration 30: delta = 0.003582911554265128\n",
      " Iteration 40: delta = 0.002025721658941382\n",
      " Iteration 50: delta = 0.0012296631676672054\n",
      " Iteration 60: delta = 0.0007832957211909575\n",
      " Iteration 70: delta = 0.0005166011500353507\n",
      " Iteration 80: delta = 0.00034975682035845446\n",
      " Iteration 90: delta = 0.00024169207441615548\n",
      " Iteration 100: delta = 0.0001697798060796285\n",
      " Iteration 110: delta = 0.00012087956026496371\n",
      " Iteration 120: delta = 8.703553752259507e-05\n",
      " Iteration 130: delta = 6.326624702621131e-05\n",
      " Iteration 140: delta = 4.6365245138263456e-05\n",
      " Iteration 150: delta = 3.422062766472722e-05\n",
      " Iteration 160: delta = 2.5414164120218796e-05\n",
      " Iteration 170: delta = 1.8977578836260056e-05\n",
      " Iteration 180: delta = 1.4240323761960383e-05\n",
      " Iteration 190: delta = 1.0732263479140691e-05\n",
      " Iteration 200: delta = 8.1201981743384e-06\n",
      " Iteration 210: delta = 6.165723455464622e-06\n",
      " Iteration 220: delta = 4.696818897087507e-06\n",
      " Iteration 230: delta = 3.5884290448540135e-06\n",
      " Iteration 240: delta = 2.7490285773867917e-06\n",
      " Iteration 250: delta = 2.111226314882586e-06\n",
      " Iteration 260: delta = 1.6251297991765057e-06\n",
      " Iteration 270: delta = 1.2536182806832663e-06\n",
      " Iteration 280: delta = 9.689485786779084e-07\n",
      " Iteration 290: delta = 7.503005094444681e-07\n",
      " Iteration 300: delta = 5.819902236803287e-07\n",
      " Iteration 310: delta = 4.5216198471531577e-07\n",
      " Iteration 320: delta = 3.518250661083133e-07\n",
      " Iteration 330: delta = 2.7414119341262477e-07\n",
      " Iteration 340: delta = 2.138949400098955e-07\n",
      " Iteration 350: delta = 1.670984429158473e-07\n",
      " Iteration 360: delta = 1.3069522203368322e-07\n",
      " Iteration 370: delta = 1.0233745673104977e-07\n",
      " Iteration 380: delta = 8.021794029033913e-08\n",
      " Iteration 390: delta = 6.294289545127896e-08\n",
      " Iteration 400: delta = 4.9435435800493366e-08\n",
      " Iteration 410: delta = 3.886209171133359e-08\n",
      " Iteration 420: delta = 3.057674793915943e-08\n",
      " Iteration 430: delta = 2.4077766974661685e-08\n",
      " Iteration 440: delta = 1.8975122056952287e-08\n",
      " Iteration 450: delta = 1.4965153033452694e-08\n",
      " Iteration 460: delta = 1.1811137123896032e-08\n",
      " Iteration 470: delta = 9.328307931655289e-09\n",
      " Iteration 480: delta = 7.37228553204794e-09\n",
      " Iteration 490: delta = 5.83012388366555e-09\n",
      " Iteration 500: delta = 4.613374737783005e-09\n",
      " Iteration 510: delta = 3.6527051383572484e-09\n",
      " Iteration 520: delta = 2.8937141294260726e-09\n",
      " Iteration 530: delta = 2.2936784416227596e-09\n",
      " Iteration 540: delta = 1.8190163819653549e-09\n",
      " Iteration 550: delta = 1.4433098882715711e-09\n",
      " Iteration 560: delta = 1.1457600423980807e-09\n",
      " Iteration 570: delta = 9.099792031008747e-10\n",
      " Iteration 580: delta = 7.230460119522775e-10\n",
      " Iteration 590: delta = 5.747651521392783e-10\n",
      " Iteration 600: delta = 4.57086757332803e-10\n",
      " Iteration 610: delta = 3.6365074840283285e-10\n",
      " Iteration 620: delta = 2.8942917507102095e-10\n",
      " Iteration 630: delta = 2.304446633516477e-10\n",
      " Iteration 640: delta = 1.8354909259166163e-10\n",
      " Iteration 650: delta = 1.4624940147811571e-10\n",
      " Iteration 660: delta = 1.1657030896117249e-10\n",
      " Iteration 670: delta = 9.294554015326639e-11\n",
      " Iteration 680: delta = 7.413306080117366e-11\n",
      " Iteration 690: delta = 5.914715939248083e-11\n",
      " Iteration 700: delta = 4.7205295228280875e-11\n",
      " Iteration 710: delta = 3.7685854437086164e-11\n",
      " Iteration 720: delta = 3.009492655081658e-11\n",
      " Iteration 730: delta = 2.4039853441237824e-11\n",
      " Iteration 740: delta = 1.9208357127098452e-11\n",
      " Iteration 750: delta = 1.5352052962214202e-11\n",
      " Iteration 760: delta = 1.2273182470323718e-11\n",
      " Iteration 770: delta = 9.814288270959537e-12\n",
      " Iteration 780: delta = 7.849998429065863e-12\n",
      " Iteration 790: delta = 6.280337361275201e-12\n",
      " Iteration 800: delta = 5.025785343448774e-12\n",
      " Iteration 810: delta = 4.022726596275561e-12\n",
      " Iteration 820: delta = 3.220618216559501e-12\n",
      " Iteration 830: delta = 2.579020330628623e-12\n",
      " Iteration 840: delta = 2.065625448466335e-12\n",
      " Iteration 850: delta = 1.654842929355027e-12\n",
      " Iteration 860: delta = 1.32596711388544e-12\n",
      " Iteration 870: delta = 1.0627054791711998e-12\n",
      " Iteration 880: delta = 8.518741267948826e-13\n",
      " Iteration 890: delta = 6.829814491737807e-13\n",
      " Iteration 900: delta = 5.476730180475897e-13\n",
      " Iteration 910: delta = 4.3931525084417444e-13\n",
      " Iteration 920: delta = 3.523847880160247e-13\n",
      " Iteration 930: delta = 2.8274604879641174e-13\n",
      " Iteration 940: delta = 2.2687407508215074e-13\n",
      " Iteration 950: delta = 1.8207657603852567e-13\n",
      " Iteration 960: delta = 1.461886167675175e-13\n",
      " Iteration 970: delta = 1.1735057370287905e-13\n",
      " Iteration 980: delta = 9.425793479067579e-14\n",
      " Iteration 990: delta = 7.566169912820442e-14\n",
      " Iteration 1000: delta = 6.078471059822732e-14\n",
      " Iteration 1010: delta = 4.884981308350689e-14\n",
      " Iteration 1020: delta = 3.9246383920499284e-14\n",
      " Iteration 1030: delta = 3.1530333899354446e-14\n",
      " Iteration 1040: delta = 2.5340840537069198e-14\n",
      " Iteration 1050: delta = 2.0344836926255994e-14\n",
      " Iteration 1060: delta = 1.6403545188836688e-14\n",
      " Iteration 1070: delta = 1.3183898417423734e-14\n",
      " Iteration 1080: delta = 1.0574874309554616e-14\n",
      " Iteration 1090: delta = 8.493206138382448e-15\n",
      " Iteration 1100: delta = 6.855627177060342e-15\n",
      " Iteration 1110: delta = 5.495603971894525e-15\n",
      " Iteration 1120: delta = 4.413136522884997e-15\n",
      " Iteration 1130: delta = 3.552713678800501e-15\n",
      " Iteration 1140: delta = 2.8449465006019636e-15\n",
      " Iteration 1150: delta = 2.3314683517128287e-15\n",
      " Iteration 1160: delta = 1.8596235662471372e-15\n",
      " Iteration 1170: delta = 1.4988010832439613e-15\n",
      " Iteration 1180: delta = 1.2212453270876722e-15\n"
     ]
    }
   ],
   "source": [
    "values = np.zeros(MAX_MONEY + 1)\n",
    "\n",
    "condition = True\n",
    "n = 0\n",
    "while condition:\n",
    "    n = n+1\n",
    "    delta = 0\n",
    "    next_values = np.zeros(MAX_MONEY + 1)\n",
    "    for s in STATES:\n",
    "        previous_values = values\n",
    "        value_s = 0\n",
    "\n",
    "        for a in ACTIONS:\n",
    "            policy_proba = policy.loc[s, a]\n",
    "            try:\n",
    "                res_eval = evalAction(s, a, previous_values)\n",
    "            except:\n",
    "                continue\n",
    "            value_s = value_s + policy_proba * res_eval\n",
    "\n",
    "        next_values[s] = value_s\n",
    "        delta = max(delta, abs(value_s - previous_values[s]))\n",
    "    values = next_values\n",
    "    if n % 10 == 0:\n",
    "        print(f' Iteration {n}: delta = {delta}')\n",
    "    condition = delta > THETA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98ca584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop:\n",
    "policy = [1 for s in STATES]\n",
    "policy = [min(s, MAX_MONEY - s) for s in STATES]\n",
    "values = np.zeros(MAX_MONEY + 1)\n",
    "while True:\n",
    "#     delta <- 0\n",
    "    delta = 0\n",
    "\n",
    "#     Loop for each s in S:\n",
    "    for s in STATES:\n",
    "\n",
    "#         v <- V(s)\n",
    "        oldvalue = values[s]\n",
    "\n",
    "#         V(s) <- sum_a ...\n",
    "        action = policy[s]\n",
    "        values[s] = evalAction(s, action, values)\n",
    "#         (this part might require multiple lines of code)\n",
    "\n",
    "#         delta <- max(delta, |v - V(s)|)\n",
    "        delta = max(delta, abs(oldvalue - values[s]))\n",
    "\n",
    "#     until delta < THETA\n",
    "    if delta < THETA:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a127c3b7",
   "metadata": {},
   "source": [
    "Plot the value function you computed above.\n",
    "Depending on your implementation, it might look nicer to ignore the terminal states (`0`, `MAX_MONEY`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3aa71539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGeCAYAAABGlgGHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0AUlEQVR4nO3df3RU9Z3/8dfMhEwQSALE/IAGE4FWEJRfJsbY069tLCqyq3X3UIqC1NqjhS6Ss1tADSzrkeB2y5dupXJ0F93vqRbrVt0qigejuILBKEgri4AoFFZJAClJBElk5vP9A++QwATmzq97Z+b5OCdnl8md5MM9befN5/N6v6/HGGMEAADgEK/TCwAAAJmNYgQAADiKYgQAADiKYgQAADiKYgQAADiKYgQAADiKYgQAADiKYgQAADiKYgQAADgqy+kFRCIYDOrTTz9Vv3795PF4nF4OAACIgDFG7e3tGjRokLzec+x/GJveeOMNc+ONN5qSkhIjyTz33HPnfc/rr79uxo4da7Kzs83QoUPN448/but37t+/30jiiy+++OKLL75S8Gv//v3n/Jy3vTNy7NgxXX755frhD3+o733ve+e9fs+ePZo0aZLuuusuPfnkk2poaNCPfvQjlZSUaOLEiRH9zn79+kmS9u/fr9zcXLtLBgAADmhra1NpaWnoc7wnHmOif1Cex+PRc889p5tuuqnHa+bNm6c1a9Zo27Ztode+//3v6+jRo1q7dm1Ev6etrU15eXlqbW2lGAEAIEVE+vmd8ABrY2Ojampqur02ceJENTY29viejo4OtbW1dfsCAADpKeHFSHNzs4qKirq9VlRUpLa2Nn3xxRdh31NfX6+8vLzQV2lpaaKXCQAAHOLK1t4FCxaotbU19LV//36nlwQAABIk4a29xcXFamlp6fZaS0uLcnNz1bt377Dv8fv98vv9iV4aAABwgYTvjFRVVamhoaHba+vWrVNVVVWifzUAAEgBtouRzz//XFu3btXWrVslnWrd3bp1q/bt2yfp1BHL9OnTQ9ffdddd+vjjj/Wzn/1MO3bs0K9//Wv97ne/09y5c+PzNwAAACnNdjHy7rvvauzYsRo7dqwkqba2VmPHjtXChQslSQcOHAgVJpJUXl6uNWvWaN26dbr88sv1i1/8Qv/2b/8W8YwRAACQ3mKaM5IszBkBACD1RPr5nRLPpgEAALELBI2a9hzRwfYTKuyXo4ryAfJ5nX/mG8UIAAAZYO22A1r8wnYdaD0Req0kL0eLJo/UdaNKHFyZS+eMAACA+Fm77YDu/s2WboWIJDW3ntDdv9mitdsOOLSyUyhGAABIY4Gg0eIXtitcQNR6bfEL2xUIOhchpRgBACCNNe05ctaOSFdG0oHWE2racyR5izoDxQgAAGnsYHvPhUg01yUCxQgAAGmssF9OXK9LBIoRAADSWEX5AJXk9VxoeHSqq6aifEDyFnUGihEAANKYz+vRj64uD/s9a8LIoskjHZ03wpwRAADSUNcBZy/86VTrrscjdZ27XuySOSMUIwAApJlwA84k6eYxg/Tse5+qbOAFqv/eZUxgBQAA8WcNOAs3NeTZ9z6VJOX27qWqoQOTu7BzIDMCAECaONeAszOvcxOKEQAA0sT5BpxZ2k+cTMJqIkcxAgBAmoh0cFnnyWCCV2IPxQgAAGkgEDQ63N4R0bUuyKx2Q4AVAIAU11P3TE+yfO7ai6AYAQAghZ2re6Yrj04/pTdoCLACAIA4iLR7Rjo14GzB9d8Ivc9NKEYAAEhRkXbP1E0aoQ3zvq2rh18oiWIEAADESaTdMwX9/PJ5PaFpqxzTAACAuCjs1/PTeMNdl/VVMXKSnREAABAPFeUDdGHf7B6/75FUkpejivIBkiSv51Qx4rZjGrppAABIMV2fyNs3p5cOfd551jXWKJFFk0eGjmes/0sxAgAAotbTTJF+OVndxrwX5+Vo0eSRum5USeg1ihEAABCTc80UaT9xUnNrhqusoI8K+506mvGdMWqVYgQAAETtfDNFPJJWv7NfG+Z9+6wixBIqRuimAQAAdp1vpoiRdKD1hJr2HOnxGt9XAVZjpKCLdkcoRgAAcLlA0Gjj7sMRXXuu2SNZ3tMf+27aHeGYBgAAF7P7ELxzzR7pUosoEDTq5Yt1dfFBMQIAgEtF+hA86VRmpLjLTJFwumZJ3BRi5ZgGAAAXsvMQvHAzRcLpVoxwTAMAAM4l0ofgSeFnioRjBVglKRCgGAEAAGFY01Vf3nYgoutnXzNUc6/9xjl3RCzsjAAAgHOyG1aVpOphF0ZUiEiSx+OR1yMFXdbaSzECAIAL2AmrSpEFVsPJ8nrVGQi66sm9BFgBAHCYnbCqFHlgNRyrvddN3TTsjAAA4DA7YVUp8sBqOFaIlWIEAACEnGtqalfTqy7S9aNKwj4EL1JufD4NxQgAAA4719TUrq4fVaKqoQNj+l1ufHIvmREAABwUCBoFg0a5OT3vD3gklUQRVg3H91VoxE3FCDsjAAA4JJJW3ljCquH4CLACAAAp8lbeWMKq4WSxMwIAACJp5c3v3Usrpo3TlRcPjMuOiCXU2uuiACuZEQAAkiySVt6jX3wpr8cT10JEcufOCMUIAABJFmkrb6TX2WHVNm4qRjimAQAgSayH4H3Y0h7R9ZG2/NrhxtZeihEAAJLAzkPwon3uTCRo7QUAIAPZeQhevFt5z0RrLwAAGcbuQ/Di3cp7JnZGAADIIIGg0RMb90R0NDP7mmGqHlYQ03NnIuGzAqwuau2lGAEAIAHsZEQkaXhR35ifOxMJN7b2UowAABBndjIilkR0zoTjJTMCAEB6s5sRSWTnTDhubO1l6BkAAHEUyXRVS6I7Z8IhwAoAQJqyBpq9vO1AxO9JdOdMOD4msAIAkH7shlUlqW7SCN1eXZ60HRFLaGeEbhoAANKD3bCqlRFxohCR3Dn0jMwIAABRiiasKiU3I3ImN7b2RlWMrFixQmVlZcrJyVFlZaWamprOef3y5cv1jW98Q71791Zpaanmzp2rEyfi/yRCAACSxc5AM0txXo4euXVcUjMiZ/K6sJvG9jHN008/rdraWq1cuVKVlZVavny5Jk6cqJ07d6qwsPCs65966inNnz9fq1at0lVXXaVdu3bp9ttvl8fj0bJly+LylwAAIJnsZkSmV12k60eVJHy6aiTcGGC1vTOybNky3XnnnZo5c6ZGjhyplStX6oILLtCqVavCXv/WW2+purpaP/jBD1RWVqbvfve7mjp16nl3UwAAcCMrI2JnR+T6USWqGjrQ8UJEcmeA1VYx0tnZqc2bN6umpub0D/B6VVNTo8bGxrDvueqqq7R58+ZQ8fHxxx/rpZde0g033NDj7+no6FBbW1u3LwAAnBIIGjV+9Jme2/K/uve5bbYyIiVJHGgWCTcGWG0d0xw+fFiBQEBFRUXdXi8qKtKOHTvCvucHP/iBDh8+rKuvvlrGGJ08eVJ33XWX7r333h5/T319vRYvXmxnaQAAJEQ0bbuSO8Kq4bhx6FnCu2nWr1+vJUuW6Ne//rW2bNmiZ599VmvWrNEDDzzQ43sWLFig1tbW0Nf+/fsTvUwAAM4SzZGMxQ1h1XBSfmekoKBAPp9PLS0t3V5vaWlRcXFx2PfU1dXptttu049+9CNJ0ujRo3Xs2DH9+Mc/1n333Sev9+x6yO/3y+/321kaAABxZbdttyunBppFIuVbe7OzszV+/Hg1NDSEXgsGg2poaFBVVVXY9xw/fvysgsPn80mSjIvCMwAAdGXnGTMWKyPi1kJEkryer1p7XfQZbLu1t7a2VjNmzNCECRNUUVGh5cuX69ixY5o5c6Ykafr06Ro8eLDq6+slSZMnT9ayZcs0duxYVVZWavfu3aqrq9PkyZNDRQkAAG5zsD09MiJnyvKlwZyRKVOm6NChQ1q4cKGam5s1ZswYrV27NhRq3bdvX7edkPvvv18ej0f333+/PvnkE1144YWaPHmyHnzwwfj9LQAAiKNA0Ohwe4et9zjx0LtohHZGXFSMeEwKnJW0tbUpLy9Pra2tys3NdXo5AIA0Zqd7ZkCfXqq78VIV5+a4YqBZJH7+yg6teP0j3X5Vmf7xry5N6O+K9PObB+UBAPCVSB96Z5UcS24e7fqdkDO5sbWXYgQAANnrnkmVI5lwfOkQYAUAIB1F2j3j5rbdSIQCrAH3FCMJH3oGAEAqiLR7pqCfP2ULESlNWnsBAEgngaBR054j+rClPaLrC/vlJHhFiZXldV83DcUIACBj2emc8ehUVsRND72LhpdiBAAAd4i0c0ZKnYFmkfgqMkIxAgCAk+w+dyaVu2fO5PPR2gsAgOMi7ZyZfc0wVQ8rSJmBZpGwWntPUowAAOCMQNBo4+7DEV07vKivqoYOTPCKkssKsAbppgEAIPnsBFal1O+cCYcAKwAADrEbWE2Hzplw3Njay9AzAEDasxNYTafOmXDYGQEAwAGRBlal9OqcCSf0bBqKEQAAEs+arvrytgMRXT/7mqGae+030nJHxGL93RgHDwBAgtkNq0pS9bAL07oQkU4XI7T2AgCQQHbCqlJ6B1bPFGrtdVExQoAVAJBW7E5XTffA6pkIsAIAkECBoNETG/fYOppJ98DqmdzY2ksxAgBIC3YzItOrLtL1o0rSatR7JLweAqwAAMSd3YyIJF0/qiTtRr1HIsvHzggAAHEVTUYkU8Kq4XiZMwIAQHxYM0Q27j4U8dFMpoVVw/GRGQEAIHbRzBCRMi+sGg4BVgAAYhRNPkSS6iaN0O3V5Rm7I2IhwAoAQJQCQaNNH32m+b9/31YhYmVEKEROIcAKAEAUoj2WISNyNgKsAADYFO2xjERGJBwyIwAA2GC3bdcy+5phqh5WkHEDzSJBNw0AADY07Tli62jGyofMvfbrFCE94Nk0AABEwJoh8vK2AxG/h3xIZELHNHTTAAAQHjNEEqtrgNUYI4/H+cKNYgQA4BrRhFXze/fSimnjdOXFA9kRiUBWl3sUNJLPBbeMYgQA4CjrSKa59Qs9sOYDW8+YkaSlt4xW9bCCRC0v7Xi7FCOBoHFFAUcxAgBwTLRHMhLHMtHKOqMYcQOKEQCAI6KdHzK96iJdP6qEtt0odb1nbgmxUowAAJIq2rHulutHlahq6MC4rytTeLsEVgMBihEAQIaJ5VjGmiFSUT4g/gvLIFnsjAAAMlUsY92ZIRI/ZwZY3YBiBACQMNF2ypyJsGp8ZXk9Ohk0FCMAgPQWy5GMJA3o00t1N16q4twcwqpx5vV6pKDhmAYAkL7icSSz5ObR7IQkSJbXo04RYAUApKFYO2UkjmSSwedx1/NpKEYAAFGx8iAH20+osF+O/nKsUw+sif5YhrHuyePzWc+nCTq8klMoRgAAtsWaB+mKse7JF9oZcUctQjECALAnljxIOBzLJJ/V3nuSnREAQKoJBI0Wv7A95kKEThlnWYPPXFKLUIwAACLXtOdITEczdMq4g5cAKwAgVR1sjy0jwpGMO2QRYAUApKrCfjlRvY9OGXdxW4DV6/QCAACpo6J8gEryIi9IPF99WZ0yFCLu4HNZgJViBAAQMZ/Xo0WTR0Z8fXFejh65dRzHMi7jI8AKAEhF1pCz9hMn1defpc87Tnb7fklejuomjVD/Pv7QIDQ6ZdzJCrC6ZWeEYgQAcF7hhpx5PdKs/zNUw4r6UXikGCvAGnRJNw3HNACAc7KGnJ3Z0hs00sOvfyR/lldVQwmmphIvAVYAQKqIZMjZ4he2KxB0x7+wERlr6JlbWnspRgAAPTrfkDMj6UDrCTXtOZK8RSFmXq+7dkbIjAAAzmKFVV/ediCi62MdhobkykqH1t4VK1aorKxMOTk5qqysVFNT0zmvP3r0qGbNmqWSkhL5/X59/etf10svvRTVggEAibV22wFd/dBrmvrYJv2/xj9H9J5oh6HBGaHWXpcEWG3vjDz99NOqra3VypUrVVlZqeXLl2vixInauXOnCgsLz7q+s7NT1157rQoLC/Wf//mfGjx4sP785z8rPz8/HusHAMSR3SfyenRqlkhF+YBELgtxFmrtDaRoMbJs2TLdeeedmjlzpiRp5cqVWrNmjVatWqX58+efdf2qVat05MgRvfXWW+rVq5ckqaysLLZVAwDizu4Tea3emUWTR9JJk2KyXLYzYuuYprOzU5s3b1ZNTc3pH+D1qqamRo2NjWHf84c//EFVVVWaNWuWioqKNGrUKC1ZskSBQKDH39PR0aG2trZuXwCAxAkEjZ7YuMfWE3mZrpq6UjrAevjwYQUCARUVFXV7vaioSDt27Aj7no8//livvfaapk2bppdeekm7d+/WT37yE3355ZdatGhR2PfU19dr8eLFdpYGAIhSuIFm5zK96iJdP6qEIWcpLONae4PBoAoLC/Xoo49q/PjxmjJliu677z6tXLmyx/csWLBAra2toa/9+/cnepkAkJF6Gmh2LtePKmHIWYo7vTPijmMaWzsjBQUF8vl8amlp6fZ6S0uLiouLw76npKREvXr1ks/nC702YsQINTc3q7OzU9nZ2We9x+/3y+/321kaAMCmaDIihFXTw+nWXncUI7Z2RrKzszV+/Hg1NDSEXgsGg2poaFBVVVXY91RXV2v37t0KdtkK2rVrl0pKSsIWIgCA5DjfQLOuCKumF58nhQOsklRbW6vHHntM//Ef/6EPPvhAd999t44dOxbqrpk+fboWLFgQuv7uu+/WkSNHNGfOHO3atUtr1qzRkiVLNGvWrPj9LQAAEQsEjRo/+izigWYSYdV043PZzojt1t4pU6bo0KFDWrhwoZqbmzVmzBitXbs2FGrdt2+fvN7TNU5paaleeeUVzZ07V5dddpkGDx6sOXPmaN68efH7WwAAImI3rCpJdZNG6PbqcnZE0kho6FmqFiOSNHv2bM2ePTvs99avX3/Wa1VVVdq0aVM0vwoAECfRDjSjEEk/bmvt5UF5AJABGGiGrtzW2suD8gAgzUU70GzR5JFkRNKUNQ4+4JIAK8UIAKQxBpohHLe19lKMAECaspsRkU4PNEN6S4sAKwDAnQJBo6Y9R9Tc+oUeWPMBA80QVsq39gIA3Cmatl2JsGomYmcEABB30RzJWAirZh4rwMrOCAAgLuy27XbFQLPMZAVY3TIOnmIEAFKcnWfMWBholtnc9tRehp4BQAoLBI027j5s6z1kREBrLwAgLqINrJIRAQFWAEDM7AZWB/TppbobL1Vxbg4DzUBrLwAgNnYCq1bJseTm0eyEIMRHgBUAEA1roNnG3YciPprhSAbhhFp7AxQjAIAIRZMPmX3NUM299hscyeAstPYCAGyJdqBZ9bALKUQQlttaeylGAMClAkGjTR99pvm/f99WIcJzZnA+tPYCAM6L58wgkQiwAgDOiefMINFCrb0EWAEAFqtTprn1Cz2w5gPbhcjsa4apelgBM0QQEZ+HnREAQBfRHslIp/Mhc6/9OkUIIsbQMwBASCxHMuRDEC3GwQMAou6U6Yp8CKIVau3lmAYAMlMsxzKSlN+7l1ZMG6crLx7IjgiikkWAFQAyixVOPdh+QnsPH9fyV3fFdCyz9JbRqh5WEM8lIsMQYAWADBLrLkhXHMsgXgiwAkCGiCWcahnQp5fqbrxUxbk5tO0ibgiwAkAGCASNFr+wPepCxCo5ltw8mp0QxB07IwCQ5gJBoyc27onpaIYjGSQSOyMAkMbolEEq8Hpo7QWAtBSPAWZ0yiAZsnxfFSPsjABA+og1I8KxDJLJau2lGAGANGDNENm4+1DERzMeSUbS3JrhKivoo8J+dMoguQiwAkCaiDYfwi4InEaAFQDSQLT5kLpJI3R7dTm7IHAUOyMAkMKifcCdR6d2RChE4AahnRG6aQAgtUR7LGOVHosmj6QQgSsQYAWAFBRL2y4ZEbjN6Z0RyRgjj8fZIpliBAB6YHXKNLd+oQfWfGC7EJl9zTBVDyugUwau0/U/j4GgCc0dcQrFCACEEcskVSsfMvfar1OEwJW6/ufyZNAoy+fgYkQxAgBnicckVfIhcLOu/9l0Q4iVYgQAvhJtp0xX5EOQCs7cGXEaxQgAiAfcIbP4ugRW3TD4jGIEQMbjAXfINOyMAIALxNopY+FYBqnI4/HI6znV2svOCAA4INYjmQF9eqnuxktVnMsD7pC6fF6PggGjAAFWAEgOaydk3fZmrdq4N6qfYZUcS24ezU4IUp7P69GXAaOTAYoRAEi4WHdCLBzJIJ1YIVZaewEgwWIJp1rolEE6ctOTeylGAKSdeIVT6ZRBOgs9n4ZiBADiK15HMhLHMkhvPq9XEjsjABAX8QinWuiUQabwnapFFKAYAYDYxGsnhE4ZZBoCrAAQJWsX5GD7Ce09fFzLX90VUzjVwpEMMo3PR4AVAGyLZx7Eckd1mWpGFnMkg4wT2hmhGAGAc4tnHqSrEnZCkOFo7QWACMR7J4RwKnAarb0AEEai8iCEU4Gz0doLADq7+Pht0z41t8UvD2IhnAqcLdTa64JuGm80b1qxYoXKysqUk5OjyspKNTU1RfS+1atXy+Px6Kabborm1wJII2u3HdDVD72mqY9t0pzVW/V/X90V90Lkjuoy/fbOK7Vh3rcpRIAzpHSA9emnn1Ztba1WrlypyspKLV++XBMnTtTOnTtVWFjY4/v27t2rv//7v9c3v/nNmBYMIPXF43kx50I4FTi/lA6wLlu2THfeeadmzpwpSVq5cqXWrFmjVatWaf78+WHfEwgENG3aNC1evFhvvvmmjh49GtOiAaSuQNBo8Qvb41aIeCQZSXNrhqusoI8K+xFOBSKRsgHWzs5Obd68WQsWLAi95vV6VVNTo8bGxh7f90//9E8qLCzUHXfcoTfffPO8v6ejo0MdHR2hP7e1tdlZJgAXa9pzJK5zQsiDANFJ2Z2Rw4cPKxAIqKioqNvrRUVF2rFjR9j3bNiwQf/+7/+urVu3Rvx76uvrtXjxYjtLA5AiDrbHpxBhWBkQm9DOSKoGWCPV3t6u2267TY899pgKCiJ//PaCBQvU2toa+tq/f38CVwkgmQr75cT0/pK8HK28dZzqJl+qqqEDKUSAKIVaewPOFyO2dkYKCgrk8/nU0tLS7fWWlhYVFxefdf1HH32kvXv3avLkyaHXgsHgqV+claWdO3dq6NChZ73P7/fL7/fbWRqAFFFRPkDFuX41t3Wc91ryIEDifPVoGle09toqRrKzszV+/Hg1NDSE2nODwaAaGho0e/bss66/5JJL9P7773d77f7771d7e7t++ctfqrS0NPqVA0gpXWeKXFE2UC/86dPzvoc8CJA41s5IygVYJam2tlYzZszQhAkTVFFRoeXLl+vYsWOh7prp06dr8ODBqq+vV05OjkaNGtXt/fn5+ZJ01usA0ldPY939WV51nAyG/lyc69fUiiHsggBJYA09S7kAqyRNmTJFhw4d0sKFC9Xc3KwxY8Zo7dq1oVDrvn375PUmNIoCIIWca6ZIx8kgRzCAQ9wUYPUY44JVnEdbW5vy8vLU2tqq3Nxcp5cDIEKBoNHVD73WYyuvR6eOYjbM+zZFCJBkP/3te3rhj59q4Y0j9cOryxPyOyL9/GYLA0DCnG+miJF0oPWEmvYcSd6iAEg6HWB1w84IxQiAhIl0pki8Zo8AiJybntpLMQIgIQJBo8Pt52/flWKfPQLAvtBTe11QjNgOsALA+fTUPXMmKzNSUT4gOQsDEGLtjFCMAEg7kT6R14qrLpo8kvAq4AB2RgCkJTtP5GWgGeAsn8c9rb0UIwBiZk1X3bj7UERP5K2bNEK3V5ezIwI4yE0BVooRADGJNB/SVUE/P4UI4DDrmCYlx8EDgCXSfMiZ6J4BnMfOCICUZycfYqF7BnAPNwVYmTMCICrnm656JrpnAHehtRdASgsEjTbuPmzrPXTPAO5iddME6KYBkGrsBlZnXzNM1cMKeCIv4DIEWAGkJDuBVSsfMvfar1OEAC7kpgArmREAEbETWCUfArgfOyMAUobdgWYS+RAgFbhpZ4RiBECPohloNvuaoZp77TfYEQFczvfVf0UJsAJwrWgHmlUPu5BCBEgBvq/OaQIBihEALhMIGm366DPN//37DDQD0hitvQBcKZpjGYnAKpCKsr767yoBVgCuEe2xjERgFUhF3q+KEQKsAFwhmufMSAw0A1JZqLWXYxoAToqmbVdioBmQDkKtvQRYATiFfAiQ2QiwAnAU+RAA1j8meGovgKSLNh+S37uXVkwbpysvHsiOCJAGKEYAOCIQNHpi4x7b+RBJWnrLaFUPK0jMwgAkXai1l2MaAMkSbUaEYxkgPYVaewmwAkiGaDIitO0C6c0KsLIzAiDh7GZEaNsFMoOPoWcAEi2aGSK07QKZw8c4eACJRD4EwPmwMwIgYaKdIVI3aYRury5nRwTIELT2Aoi7QNBo00efaf7v37dViFgZEQoRILPQ2gsgrhjtDsAur4djGgAxsMKpB9tPaO/h41r+6i5GuwOwhQArgKhFuwvSFTNEABBgBRCVWB5wJzFDBMBp7IwAsCXacGpX5EMAdJXFzgiASMXjWEYiHwKgO+vZNAG6aQCcS6zHMpKU37uXVkwbpysvHsiOCICQLOaMADgfu8+UOZNVdiy9ZbSqhxXEa1kA0oTV2ksxAuAs0TxTJhyOZQCcS1aXndJg0ISObRxZi2O/GcBZYhleZiTNrRmusoI+KuyXQ9sugHPqWnycDBplU4wAiCUfwi4IALu6/mPF6ZHwFCOAw2Jp2yWcCiBaWWfsjDiJYgRwUKzPlCGcCiBaVoBVcj7ESjECOIRjGQBO6rozQjECZKBo23Z5pgyAePFSjACZKdq2XZ4pAyARsrwenQwaAqxApog1H8IzZQDEm9frkYKGACuQCciHAHAjn8cdT+6lGAESiLZdAG7mlif3UowACULbLgC387rkYXkUI0ACcCwDIBW45cm9FCNAnFidMs2tX+iBNR/QtgvA9dgZAdJItEcyEm27AJxj7YzQ2gukKGsnZN32Zq3auDeqn0HbLgAnWSPhCbACKSiWnZCuyIcAcJLPJcc03mjetGLFCpWVlSknJ0eVlZVqamrq8drHHntM3/zmN9W/f3/1799fNTU157wecDsrnBpLIZLfu5ee/FGlNsz7NoUIAMe4JcBquxh5+umnVVtbq0WLFmnLli26/PLLNXHiRB08eDDs9evXr9fUqVP1+uuvq7GxUaWlpfrud7+rTz75JObFA8kSCBo1fvSZntvyv7r3uW1RdclIp45lPDrdtsvRDAAnuSXA6jHGXmqlsrJSV1xxhR5++GFJUjAYVGlpqX76059q/vz5531/IBBQ//799fDDD2v69OkR/c62tjbl5eWptbVVubm5dpYLxCxeRzKSVMKxDAAXuW75f2tHc7t+c0elrh4e/7lGkX5+28qMdHZ2avPmzVqwYEHoNa/Xq5qaGjU2Nkb0M44fP64vv/xSAwYM6PGajo4OdXR0hP7c1tZmZ5lA3MQyL8QyoE8v1d14qYpzc2jbBeAqVoA14HA3ja1jmsOHDysQCKioqKjb60VFRWpubo7oZ8ybN0+DBg1STU1Nj9fU19crLy8v9FVaWmpnmUDMAkGjjR8ejmqMu8U6klly82jdPHawqoYy1h2Au2T5MvDZNEuXLtXq1au1fv165eTk9HjdggULVFtbG/pzW1sbBQmShk4ZAJkiJVt7CwoK5PP51NLS0u31lpYWFRcXn/O9//Iv/6KlS5fq1Vdf1WWXXXbOa/1+v/x+v52lAVGz5oUcbD+hvYePa/mru2I6lrmjukw1I4s5kgHgem7pprFVjGRnZ2v8+PFqaGjQTTfdJOlUgLWhoUGzZ8/u8X3//M//rAcffFCvvPKKJkyYENOCgXginAogk7mlm8b2MU1tba1mzJihCRMmqKKiQsuXL9exY8c0c+ZMSdL06dM1ePBg1dfXS5IeeughLVy4UE899ZTKyspC2ZK+ffuqb9++cfyrAJGJx+RUC+FUAKnM55IAq+1iZMqUKTp06JAWLlyo5uZmjRkzRmvXrg2FWvft2yev93Qu9pFHHlFnZ6f+5m/+ptvPWbRokf7xH/8xttUDNsVrJ8QqOZbcPJqdEAApywqwBoJBZ9cRzZtmz57d47HM+vXru/1579690fwKIC7inQexEE4FkA5Crb3O1iI8mwbpK555EEt+715aMW2crryYNl0Aqe90gDUFd0YAt4pnHqQrq+ywxrgDQDo4HWB1dh0UI0hZXY9gCvvl6C/HOvXAmvjuhFg4lgGQjkI7I6kWYAXcIBFHMBaPJCNpbs1wlRX0UWE/OmUApKfQzojDWyMUI0g58XhezLmwCwIgU5xu7XV2HRQjSCmBoNHiF7YnpBBhciqATEOAFYhC054jcT+aYXIqgExFgBWwwQqrvrztQEw/hzwIAJzGzggQoXiGVcmDAMBp7IwAEYhXWJU8CACcjdZe4DziEVYlDwIAPTs9Dp5jGuAsgaDRExv32DqaKcnLUd2kEerfxx8ahMZOCAD0zMcxDRCe3YzI9KqLdP2oEgoPALCJACsQRjQZketHlahq6MCErQkA0hUBVuArVttuc+sXemDNBxEXIh6d6o6pKB+QyOUBQNpiZwRQ9G271mHMoskjOZoBgCiFAqx00yBTxdK2y7wQAIhdFsc0yFSBoNGmjz7T/N+/H1UhUjdphG6vLmdHBABi5OWYBpkolmmqVkaEQgQA4oOdEWScWI5lyIgAQPz52BlBJoi2U+ZMZEQAIP5OB1idXQfFCBIm1gfcDejTS3U3XqriXCapAkAiZPnYGUEasnZC1m1v1qqNe6P6GVbJseTm0eyEAEACnX42Da29SBOx7oRYOJIBgOQgwIq0Eks41ZLfu5dWTBunKy8eyJEMACQBrb1IefEKp1plx9JbRqt6WEG8lgcAOI/QzggBVqSieB3JSBzLAIBTaO1FyolHONVCpwwAOI8AK1JKvHZC6JQBAPc4HWClGIELWbsgB9tPaO/h41r+6q6YwqkWjmQAwD28FCNwq3jmQSx3VJepZmQxRzIA4CIEWOFK8WjR7aqEnRAAcC1ae+EqgaDRpo8+0/zfvx9zIUI4FQBSA0PP4JiueZDCfjn6y7FOPbCGcCoAZBqfh50ROCAReRAL4VQASC0EWJE08ZwPEg7hVABITbT2IikSuRNCOBUAUltoZ8RQjCCOEjUfxCPJSJpbM1xlBX1U2I9wKgCkutDOiMO9vRQjaYQ8CADAjtA4eHZGEA/xng9iye/dSyumjdOVFw9kFwQA0kyWj9ZexEE854N0ZZUdS28ZrephBXH8yQAAt6C1FzHjWAYAEAsf3TSwK1Hh1JK8HNVNGqH+ffyhQWiEUwEg/VGMwBYeXgcAiDcCrDivRA0rYz4IAEDqGmClGEEY8doJYT4IAKAnpwOsFCNQ4vIgBFEBAD2x/mEaNJIxRh6PM/9QpRhxgUTkQZgPAgA4n66fD4GgCR3bJBvFiEMSlQdhPggAIFLdihFjHCsKKEaSoOsRTGG/HP3lWKceWMN8EACAs87cGXEKxUiCJXIwGeFUAEAsvB6KkbSVqCOYM7ELAgCIRRY7I+kpkTshFoaVAQDigWOaNJGoltxwGFYGAIgnj8cjr+dUa6+TU1gpRmw6s/j4bdM+NbeRBwEApCaf16NgwLAzkiqScQRjIQ8CAEgGn9ejLylG3CuZRzAW8iAAgGRyw0j4jC1Gzpz9UVE+QJKScgQTDnkQAECyBYIm9I/szXv/oq/1v8CRfwh7jLGfWFmxYoV+/vOfq7m5WZdffrl+9atfqaKiosfrn3nmGdXV1Wnv3r0aPny4HnroId1www0R/762tjbl5eWptbVVubm5dpd7lnDHLfkX9JIkHT3+Zcw//3xK8nJUN2mE+vfxdyuG2AkBACRLuM/CeP/DONLPb9s7I08//bRqa2u1cuVKVVZWavny5Zo4caJ27typwsLCs65/6623NHXqVNXX1+vGG2/UU089pZtuuklbtmzRqFGj7P76mK3ddkB3/2bLWcctyShCOIIBALhBT5+Fza0ndPdvtuiRW8cldafe9s5IZWWlrrjiCj388MOSpGAwqNLSUv30pz/V/Pnzz7p+ypQpOnbsmF588cXQa1deeaXGjBmjlStXRvQ747UzEggaXf3Qa0kJoHbFEQwAwC3O91no0akmig3zvh3zP5wTsjPS2dmpzZs3a8GCBaHXvF6vampq1NjYGPY9jY2Nqq2t7fbaxIkT9fzzz/f4ezo6OtTR0RH6c1tbm51l9qhpz5GEFyK05AIA3Ox8n4VG0oHWE2rac0RVQwcmZU22ipHDhw8rEAioqKio2+tFRUXasWNH2Pc0NzeHvb65ubnH31NfX6/FixfbWVpEDrbTkgsAyGyRfhYm4zPT4spumgULFnTbTWlra1NpaWnMP7ewX07MP+NMxbl+Ta0Ywi4IACAlRPpZmIjPzJ7YKkYKCgrk8/nU0tLS7fWWlhYVFxeHfU9xcbGt6yXJ7/fL7/fbWVpEKsoHqCQvR82tJ6KaF8IRDAAg1Z3vs9DKjFgjL5LBa+fi7OxsjR8/Xg0NDaHXgsGgGhoaVFVVFfY9VVVV3a6XpHXr1vV4fSL5vB4tmjxS0qmbbVdxXo5W3jpOc2q+rr8eM1hVQwdSiAAAUsq5PgutPy+aPDKpn2+2j2lqa2s1Y8YMTZgwQRUVFVq+fLmOHTummTNnSpKmT5+uwYMHq76+XpI0Z84cfetb39IvfvELTZo0SatXr9a7776rRx99NL5/kwhdN6pEj9w6LqI5IxzBAADSUU+fhU7lHm0XI1OmTNGhQ4e0cOFCNTc3a8yYMVq7dm0opLpv3z55vac3XK666io99dRTuv/++3Xvvfdq+PDhev755x2ZMWK5blSJrh1ZfM4JrBQfAIB01tNnYcpMYE22eE9gBQAAiRfp57etzAgAAEC8UYwAAABHUYwAAABHUYwAAABHUYwAAABHUYwAAABHUYwAAABHUYwAAABHUYwAAABH2R4H7wRrSGxbW5vDKwEAAJGyPrfPN+w9JYqR9vZ2SVJpaanDKwEAAHa1t7crLy+vx++nxLNpgsGgPv30U/Xr108eT/we4NPW1qbS0lLt37+fZ94kEPc5ebjXycF9Tg7uc3Ik8j4bY9Te3q5BgwZ1e4jumVJiZ8Tr9eprX/tawn5+bm4u/0FPAu5z8nCvk4P7nBzc5+RI1H0+146IhQArAABwFMUIAABwVEYXI36/X4sWLZLf73d6KWmN+5w83Ovk4D4nB/c5Odxwn1MiwAoAANJXRu+MAAAA51GMAAAAR1GMAAAAR1GMAAAAR2V0MbJixQqVlZUpJydHlZWVampqcnpJKa2+vl5XXHGF+vXrp8LCQt10003auXNnt2tOnDihWbNmaeDAgerbt69uueUWtbS0OLTi9LB06VJ5PB7dc889ode4z/HxySef6NZbb9XAgQPVu3dvjR49Wu+++27o+8YYLVy4UCUlJerdu7dqamr04YcfOrji1BMIBFRXV6fy8nL17t1bQ4cO1QMPPNDtWSbc5+j893//tyZPnqxBgwbJ4/Ho+eef7/b9SO7rkSNHNG3aNOXm5io/P1933HGHPv/88/gv1mSo1atXm+zsbLNq1SrzP//zP+bOO+80+fn5pqWlxemlpayJEyeaxx9/3Gzbts1s3brV3HDDDWbIkCHm888/D11z1113mdLSUtPQ0GDeffddc+WVV5qrrrrKwVWntqamJlNWVmYuu+wyM2fOnNDr3OfYHTlyxFx00UXm9ttvN2+//bb5+OOPzSuvvGJ2794dumbp0qUmLy/PPP/88+aPf/yj+au/+itTXl5uvvjiCwdXnloefPBBM3DgQPPiiy+aPXv2mGeeecb07dvX/PKXvwxdw32OzksvvWTuu+8+8+yzzxpJ5rnnnuv2/Uju63XXXWcuv/xys2nTJvPmm2+aYcOGmalTp8Z9rRlbjFRUVJhZs2aF/hwIBMygQYNMfX29g6tKLwcPHjSSzBtvvGGMMebo0aOmV69e5plnngld88EHHxhJprGx0allpqz29nYzfPhws27dOvOtb30rVIxwn+Nj3rx55uqrr+7x+8Fg0BQXF5uf//znodeOHj1q/H6/+e1vf5uMJaaFSZMmmR/+8IfdXvve975npk2bZozhPsfLmcVIJPd1+/btRpJ55513Qte8/PLLxuPxmE8++SSu68vIY5rOzk5t3rxZNTU1ode8Xq9qamrU2Njo4MrSS2trqyRpwIABkqTNmzfryy+/7HbfL7nkEg0ZMoT7HoVZs2Zp0qRJ3e6nxH2Olz/84Q+aMGGC/vZv/1aFhYUaO3asHnvssdD39+zZo+bm5m73OS8vT5WVldxnG6666io1NDRo165dkqQ//vGP2rBhg66//npJ3OdEieS+NjY2Kj8/XxMmTAhdU1NTI6/Xq7fffjuu60mJB+XF2+HDhxUIBFRUVNTt9aKiIu3YscOhVaWXYDCoe+65R9XV1Ro1apQkqbm5WdnZ2crPz+92bVFRkZqbmx1YZepavXq1tmzZonfeeees73Gf4+Pjjz/WI488otraWt17771655139Hd/93fKzs7WjBkzQvcy3P+OcJ8jN3/+fLW1temSSy6Rz+dTIBDQgw8+qGnTpkkS9zlBIrmvzc3NKiws7Pb9rKwsDRgwIO73PiOLESTerFmztG3bNm3YsMHppaSd/fv3a86cOVq3bp1ycnKcXk7aCgaDmjBhgpYsWSJJGjt2rLZt26aVK1dqxowZDq8uffzud7/Tk08+qaeeekqXXnqptm7dqnvuuUeDBg3iPmeQjDymKSgokM/nO6u7oKWlRcXFxQ6tKn3Mnj1bL774ol5//XV97WtfC71eXFyszs5OHT16tNv13Hd7Nm/erIMHD2rcuHHKyspSVlaW3njjDf3rv/6rsrKyVFRUxH2Og5KSEo0cObLbayNGjNC+ffskKXQv+d+R2PzDP/yD5s+fr+9///saPXq0brvtNs2dO1f19fWSuM+JEsl9LS4u1sGDB7t9/+TJkzpy5Ejc731GFiPZ2dkaP368GhoaQq8Fg0E1NDSoqqrKwZWlNmOMZs+ereeee06vvfaaysvLu31//Pjx6tWrV7f7vnPnTu3bt4/7bsN3vvMdvf/++9q6dWvoa8KECZo2bVro/+c+x666uvqs1vRdu3bpoosukiSVl5eruLi4231ua2vT22+/zX224fjx4/J6u38U+Xw+BYNBSdznRInkvlZVVeno0aPavHlz6JrXXntNwWBQlZWV8V1QXOOwKWT16tXG7/ebJ554wmzfvt38+Mc/Nvn5+aa5udnppaWsu+++2+Tl5Zn169ebAwcOhL6OHz8euuauu+4yQ4YMMa+99pp59913TVVVlamqqnJw1emhazeNMdzneGhqajJZWVnmwQcfNB9++KF58sknzQUXXGB+85vfhK5ZunSpyc/PN//1X/9l/vSnP5m//uu/puXUphkzZpjBgweHWnufffZZU1BQYH72s5+FruE+R6e9vd2899575r333jOSzLJly8x7771n/vznPxtjIruv1113nRk7dqx5++23zYYNG8zw4cNp7Y23X/3qV2bIkCEmOzvbVFRUmE2bNjm9pJQmKezX448/Hrrmiy++MD/5yU9M//79zQUXXGBuvvlmc+DAAecWnSbOLEa4z/HxwgsvmFGjRhm/328uueQS8+ijj3b7fjAYNHV1daaoqMj4/X7zne98x+zcudOh1aamtrY2M2fOHDNkyBCTk5NjLr74YnPfffeZjo6O0DXc5+i8/vrrYf83ecaMGcaYyO7rZ599ZqZOnWr69u1rcnNzzcyZM017e3vc1+oxpsuYOwAAgCTLyMwIAABwD4oRAADgKIoRAADgKIoRAADgKIoRAADgKIoRAADgKIoRAADgKIoRAADgKIoRAADgKIoRAADgKIoRAADgKIoRAADgqP8PmB5KU8mC9MUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(STATES, values)\n",
    "plt.scatter(STATES, values)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "611ca345",
   "metadata": {},
   "source": [
    "Does the value function look as expected?\n",
    "How does the value function change for different policies, probabilities (`P_HEADS`), and discount factors (`GAMMA`)?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f0e5b61",
   "metadata": {},
   "source": [
    "## 3. Policy Iteration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e525645f",
   "metadata": {},
   "source": [
    "In this section, we compute the optimal policy and value function using policy iteration.\n",
    "We implement the policy evaluation and improvement steps as individual functions, which we then call alternately for the actual policy iteration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0e48df",
   "metadata": {},
   "source": [
    "\n",
    "Implement the policy evaluation step. You can use your code from above, but need to wrap it in a function that takes the current policy as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e85a696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policyEvaluation(policy):\n",
    "\n",
    "    # Loop:\n",
    "    values = np.zeros(MAX_MONEY + 1)\n",
    "    while True:\n",
    "    # delta <- 0\n",
    "        delta = 0\n",
    "\n",
    "        # Loop for each s in S:\n",
    "        for s in STATES:\n",
    "\n",
    "            # v <- V(s)\n",
    "            oldvalue = values[s]\n",
    "\n",
    "            # V(s) <- sum_a ...\n",
    "            action = policy[s]\n",
    "            values[s] = evalAction(s, action, values)\n",
    "\n",
    "            # delta <- max(delta, |v - V(s)|)\n",
    "            delta = max(delta, abs(oldvalue - values[s]))\n",
    "\n",
    "        # until delta < THETA\n",
    "        if delta < THETA:\n",
    "            break\n",
    "        \n",
    "        return values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "977b91cc",
   "metadata": {},
   "source": [
    "Implement the policy improvement step as a function that takes the current value function as an argument and returns the new (greedy) policy.\n",
    "\n",
    "*Note: In this particular example, there are multiple optimal policies. Your results might look nicer if you break ties (or almost ties) in favor of lower stakes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fa149a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policyImprovement(values):\n",
    "    for s in STATES:\n",
    "        if s in (0, MAX_MONEY):\n",
    "            continue\n",
    "        best_action = 0\n",
    "        best_value = -1\n",
    "\n",
    "        actions = range(1, min(s, MAX_MONEY - s) + 1)\n",
    "        for action in actions:\n",
    "            action_value = evalAction(s, action, values)\n",
    "            if action_value > best_value:\n",
    "                best_action = action\n",
    "                best_value = action_value\n",
    "        \n",
    "        policy[s] = best_action\n",
    "\n",
    "    return policy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "299e5061",
   "metadata": {},
   "source": [
    "Implement policy iteration, using the functions you implemented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2d9bfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize values and policy\n",
    "policy = [1 for s in STATES]\n",
    "policy[0] = 0\n",
    "policy[MAX_MONEY] = 0\n",
    "\n",
    "values = np.zeros(MAX_MONEY + 1)\n",
    "\n",
    "# Do policy iteration\n",
    "while True:\n",
    "\n",
    "    # Policy evaluation\n",
    "    values = policyEvaluation(policy)\n",
    "\n",
    "    # Policy improvement\n",
    "    new_policy = policyImprovement(values)\n",
    "\n",
    "    # Check if policy has changed\n",
    "    if policy == new_policy:\n",
    "        break\n",
    "\n",
    "    # Update policy\n",
    "    policy = new_policy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "260a694c",
   "metadata": {},
   "source": [
    "Plot the optimal value function and the optimal policy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "437ac65f",
   "metadata": {},
   "source": [
    "## 4. Value Iteration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d30453a2",
   "metadata": {},
   "source": [
    "In this section we compute the optimal policy and value function using value iteration.\n",
    "Again, we follow the pseudo-code from Sutton & Barto (p. 83)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f204e031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize values\n",
    "\n",
    "# Loop:\n",
    "    # delta <- 0\n",
    "\n",
    "    # Loop for each s in S:\n",
    "        # v <- V(s)\n",
    "\n",
    "        # V(s) <- max_a sum_s' ...\n",
    "        # (this part might require multiple lines of code)\n",
    "\n",
    "        # delta <- max(delta, |v - V(s)|)\n",
    "\n",
    "    # until delta < THETA\n",
    "\n",
    "# Output a deterministic policy such that\n",
    "# policy[s] = argmax_a ...\n",
    "# (this part might require another loop over the states/actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0d3832",
   "metadata": {},
   "source": [
    "Plot the optimal value function and the optimal policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fe4a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ...??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2df9502",
   "metadata": {},
   "source": [
    "### 4.a Bonus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5781f4fd",
   "metadata": {},
   "source": [
    "Find and plot *all* optimal policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7832e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tolerance for \"equal\" values\n",
    "TOL_OPTIMAL = 10 * THETA\n",
    "\n",
    "\n",
    "# Initialize empty policy\n",
    "# This time, this will be a list of lists\n",
    "policy = []\n",
    "\n",
    "# Loop for each state\n",
    "for state in STATES:\n",
    "    # If we are in a terminal state, do nothing\n",
    "    if state == 0 or state == MAX_MONEY:\n",
    "        policy.append([])\n",
    "        continue\n",
    "\n",
    "    # Evaluate all actions\n",
    "    # ...??\n",
    "    \n",
    "    # Choose all optimal actions\n",
    "    # ...??\n",
    "\n",
    "    # Append best actions to policy\n",
    "    # ...??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149fd573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot with all optimal state/action pairs\n",
    "# ...?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6f4eca8",
   "metadata": {},
   "source": [
    "### 4.b Bonus 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36049ea4",
   "metadata": {},
   "source": [
    "Ideas for further exploration:\n",
    "- How does the set of *all* optimal policies behave for different values of `MAX_MONEY`? *Hint: Powers of 2 are particularly interesting!*\n",
    "- Change the code above to allow bets which would cause the player to have more than $100 after a win. Does this change the optimal policy?\n",
    "- Change the policy evaluation code to allow for non-deterministic policies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "275c90bd5bb82664c788af040251692cc03dc86a881c38c70c21622899dbd0c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
